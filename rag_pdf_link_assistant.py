# -*- coding: utf-8 -*-
"""RAG-Pdf/Link-Assistant.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BSUU7VX9nEuxwMVV_Y4NrSjUxTwLCc-m
"""

!pip install gradio langchain langchain-community langchain-google-genai faiss-cpu unstructured

# Imports
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from bs4 import BeautifulSoup
import gradio as gr

# LLM and Embeddings
import os
API_KEY = os.getenv("GEMINI_API_KEY")


llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    google_api_key=API_KEY,
    temperature=0.2
)

embeddings = GoogleGenerativeAIEmbeddings(
    model="models/text-embedding-004",
    google_api_key=API_KEY
)

# Globals
vectorstore = None
retrievalQA = None

# PromptTemplate
PROMPT_TEMPLATE = PromptTemplate(
    template="""You are an expert assistant.
Answer questions clearly and concisely using ONLY the provided content.

Content:
{context}

Question: {question}

If the answer is not in the content, say "I don‚Äôt know.".""",
    input_variables=["context", "question"]
)

# Text Cleaning
def clean_url_text(content):
    soup = BeautifulSoup(content, "html.parser")
    for tag in soup(["script", "style", "header", "footer", "nav"]):
        tag.decompose()
    text = soup.get_text(separator=" ")
    return " ".join(text.split())

# Processing PDF
def process_pdf(file):
    global vectorstore, retrievalQA
    try:
        if file is None:
            return "‚ö†Ô∏è Please upload a PDF first."

        file_path = file.name if hasattr(file, "name") else file['name']

        loader = PyPDFLoader(file_path)
        pages = loader.load()
        if not pages:
            return "‚ùå PDF is empty or could not be read."

        splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=30)
        docs = splitter.split_documents(pages)

        if vectorstore:
            vectorstore.add_documents(docs)
        else:
            vectorstore = FAISS.from_documents(docs, embeddings)

        retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 3})

        retrievalQA = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT_TEMPLATE},
        )
        return "‚úÖ PDF processed successfully! You can now ask questions."
    except Exception as e:
        return f"‚ùå Error processing PDF: {e}"

# Processing URL
def process_url(url):
    global vectorstore, retrievalQA
    try:
        if not url.strip():
            return "‚ö†Ô∏è Please enter a URL first."

        loader = WebBaseLoader(url)
        docs = loader.load()
        if not docs:
            return "‚ùå Failed to load URL or empty content."

        cleaned = clean_url_text(docs[0].page_content)
        doc = Document(page_content=cleaned, metadata={"source": url})

        splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=200)
        chunks = splitter.split_documents([doc])

        if vectorstore:
            vectorstore.add_documents(chunks)
        else:
            vectorstore = FAISS.from_documents(chunks, embeddings)

        retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 3})

        retrievalQA = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT_TEMPLATE},
        )
        return "‚úÖ URL processed successfully! You can now ask questions."
    except Exception as e:
        return f"‚ùå Error processing URL: {e}"

# Query Handling
def ask_question(query):
    try:
        if retrievalQA is None:
            return "‚ö†Ô∏è Please upload a PDF or enter a URL first."

        result = retrievalQA.invoke({"query": query})
        return result["result"].strip()
    except Exception as e:
        return f"‚ùå Error: {e}"

# Gradio UI
with gr.Blocks() as demo:
    gr.Markdown("## üåê Unified PDF + Webpage RAG Assistant")
    gr.Markdown("Upload PDFs or enter webpage URLs. Then ask questions about all loaded content.")

    with gr.Row():
        with gr.Column():
            pdf_input = gr.File(label="Upload PDF")
            pdf_btn = gr.Button("Process PDF")
            url_input = gr.Textbox(label="Enter Webpage URL")
            url_btn = gr.Button("Process URL")
            status = gr.Textbox(label="Status")

        with gr.Column():
            query_input = gr.Textbox(label="Ask a Question")
            ask_btn = gr.Button("Ask")
            answer_output = gr.Textbox(label="Answer", lines=8)

    pdf_btn.click(process_pdf, inputs=pdf_input, outputs=status)
    url_btn.click(process_url, inputs=url_input, outputs=status)
    ask_btn.click(ask_question, inputs=query_input, outputs=answer_output)

demo.launch()