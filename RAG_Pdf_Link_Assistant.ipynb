{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TRaHe4ezzHrl",
        "outputId": "9cc18697-a4d2-4001-9ea9-a8e2fa9262a5"
      },
      "outputs": [],
      "source": [
        "!pip install gradio langchain langchain-community langchain-google-genai faiss-cpu unstructured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wgnNr9R-0Ab8"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from bs4 import BeautifulSoup\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpOpe8Z40UHK"
      },
      "outputs": [],
      "source": [
        "# LLM and Embeddings\n",
        "import os\n",
        "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    google_api_key=API_KEY,\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    google_api_key=API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "BK4D2zGh0bw_"
      },
      "outputs": [],
      "source": [
        "# Globals\n",
        "vectorstore = None\n",
        "retrievalQA = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zCXf8cdm0fLV"
      },
      "outputs": [],
      "source": [
        "# PromptTemplate\n",
        "PROMPT_TEMPLATE = PromptTemplate(\n",
        "    template=\"\"\"You are an expert assistant.\n",
        "Answer questions clearly and concisely using ONLY the provided content.\n",
        "\n",
        "Content:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "If the answer is not in the content, say \"I don‚Äôt know.\".\"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bB19e5pQ0itJ"
      },
      "outputs": [],
      "source": [
        "# Text Cleaning\n",
        "def clean_url_text(content):\n",
        "    soup = BeautifulSoup(content, \"html.parser\")\n",
        "    for tag in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\"]):\n",
        "        tag.decompose()\n",
        "    text = soup.get_text(separator=\" \")\n",
        "    return \" \".join(text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OQYPGT7q0q1l"
      },
      "outputs": [],
      "source": [
        "# Processing PDF\n",
        "def process_pdf(file):\n",
        "    global vectorstore, retrievalQA\n",
        "    try:\n",
        "        if file is None:\n",
        "            return \"‚ö†Ô∏è Please upload a PDF first.\"\n",
        "\n",
        "        file_path = file.name if hasattr(file, \"name\") else file['name']\n",
        "\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        pages = loader.load()\n",
        "        if not pages:\n",
        "            return \"‚ùå PDF is empty or could not be read.\"\n",
        "\n",
        "        splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=30)\n",
        "        docs = splitter.split_documents(pages)\n",
        "\n",
        "        if vectorstore:\n",
        "            vectorstore.add_documents(docs)\n",
        "        else:\n",
        "            vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "        retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "\n",
        "        retrievalQA = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=retriever,\n",
        "            return_source_documents=True,\n",
        "            chain_type_kwargs={\"prompt\": PROMPT_TEMPLATE},\n",
        "        )\n",
        "        return \"‚úÖ PDF processed successfully! You can now ask questions.\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error processing PDF: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3A7yNcL70zNo"
      },
      "outputs": [],
      "source": [
        "# Processing URL\n",
        "def process_url(url):\n",
        "    global vectorstore, retrievalQA\n",
        "    try:\n",
        "        if not url.strip():\n",
        "            return \"‚ö†Ô∏è Please enter a URL first.\"\n",
        "\n",
        "        loader = WebBaseLoader(url)\n",
        "        docs = loader.load()\n",
        "        if not docs:\n",
        "            return \"‚ùå Failed to load URL or empty content.\"\n",
        "\n",
        "        cleaned = clean_url_text(docs[0].page_content)\n",
        "        doc = Document(page_content=cleaned, metadata={\"source\": url})\n",
        "\n",
        "        splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=200)\n",
        "        chunks = splitter.split_documents([doc])\n",
        "\n",
        "        if vectorstore:\n",
        "            vectorstore.add_documents(chunks)\n",
        "        else:\n",
        "            vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "        retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "\n",
        "        retrievalQA = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=retriever,\n",
        "            return_source_documents=True,\n",
        "            chain_type_kwargs={\"prompt\": PROMPT_TEMPLATE},\n",
        "        )\n",
        "        return \"‚úÖ URL processed successfully! You can now ask questions.\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error processing URL: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "T3NxxWLN07vL"
      },
      "outputs": [],
      "source": [
        "# Query Handling\n",
        "def ask_question(query):\n",
        "    try:\n",
        "        if retrievalQA is None:\n",
        "            return \"‚ö†Ô∏è Please upload a PDF or enter a URL first.\"\n",
        "\n",
        "        result = retrievalQA.invoke({\"query\": query})\n",
        "        return result[\"result\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "LlT5qFij1AeG",
        "outputId": "7273c7d3-1159-4761-8942-33d08948c654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5290aea5c26b026935.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5290aea5c26b026935.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üåê Unified PDF + Webpage RAG Assistant\")\n",
        "    gr.Markdown(\"Upload PDFs or enter webpage URLs. Then ask questions about all loaded content.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            pdf_input = gr.File(label=\"Upload PDF\")\n",
        "            pdf_btn = gr.Button(\"Process PDF\")\n",
        "            url_input = gr.Textbox(label=\"Enter Webpage URL\")\n",
        "            url_btn = gr.Button(\"Process URL\")\n",
        "            status = gr.Textbox(label=\"Status\")\n",
        "\n",
        "        with gr.Column():\n",
        "            query_input = gr.Textbox(label=\"Ask a Question\")\n",
        "            ask_btn = gr.Button(\"Ask\")\n",
        "            answer_output = gr.Textbox(label=\"Answer\", lines=8)\n",
        "\n",
        "    pdf_btn.click(process_pdf, inputs=pdf_input, outputs=status)\n",
        "    url_btn.click(process_url, inputs=url_input, outputs=status)\n",
        "    ask_btn.click(ask_question, inputs=query_input, outputs=answer_output)\n",
        "\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
